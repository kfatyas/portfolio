# -*- coding: ISO-8859-1 -*-
"""
Created on Mon Jun 3 12:04:03 2019
Applying Machine Learning to predict outliers based on training dataset
@author: Kevin Fatyas
@source: https://surveys-enquetes.statcan.gc.ca/cannabis/

Sample of interactive report can be located in the below:
https://app.powerbi.com/view?r=eyJrIjoiMjdmZDZkNjQtYWJmMS00ZWZhLWEyNzEtZGU4MTU2ODViNzhkIiwidCI6IjA5Mjg0MzdlLTFhZTItNGJhNy1hZmQxLTY5NDhmY2I5MWM0OCJ9
"""

import matplotlib.pyplot as plt
import pandas as pd
import sklearn.svm as svm
from sklearn.model_selection import train_test_split as tts
from sklearn.metrics import accuracy_score
import warnings

warnings.filterwarnings("ignore")

# skiprows removes pre-table text, allows us to start with our data features as column headers.
csource = pd.read_csv('May13_EN.csv', skiprows=5, na_values=['NA'], encoding = 'ISO-8859-1')

#---------------------------------------------------------------------------------------------------------------------------
# Checking for Outliers
# Stats Canada already omits outliers in the dataset provided. Below is an alternative calculation.
# #Let's compare the original data set with the data where we filter out outliers.
#---------------------------------------------------------------------------------------------------------------------------

'''
Step 1: PLOT DATA
Let's see what our quantity and price data looks like on a scatter plot to explore where our outliers might be.
'''
print("Let's plot quantity vs. price on a scatterplot and visualize where our outliers might be.")

cdata = csource[csource['Outlier'] != 1]
coutlier = csource[csource['Outlier'] != 0]


plt.title('Observing Quantity vs Price for Cannabis Acquisition')
plt.scatter(coutlier['Quantity'], coutlier['Price'], alpha = 0.5, color = 'crimson')
plt.scatter(cdata['Quantity'], cdata['Price'], alpha = 0.5, color = 'teal')
plt.axis([0, 10000, 0, 100])
plt.xlabel('Quantity (grams)')
plt.ylabel('Price ($)')
plt.show()


'''
Step 2: QUESTION THE DATA
How did StatsCanada define outliers? 
How close can we get to matching their outlier analysis & why are some extreme values passing through as valid submissions?
'''
print("We can see that most valid observations occur within a close range, however some values still appear to be happening at certain extremities in our plot. Why are some of these extreme values passing through as valid submissions? Let's explore using a box plot!")

#1 - BOXPLOT - lets set a confidence interval that we can explore as we make changes to our conditions
plt.title('Observing Boxplot for Expenditures ($)')
plt.boxplot(coutlier['Expenditure'], vert = False)
plt.show()

plt.title('Observing Boxplot for Expenditures ($) - Max 400')
coutlier = coutlier[coutlier['Expenditure'] <= 400]
plt.boxplot(coutlier['Expenditure'], notch = True, vert = False)
plt.show()

print("Let's try calculating the min and max values for all float-type features in our data.")

#2 - what are the min and max quantities, prices, expenditures & consumptions StatsCan is accepting in their Outlier analysis?
cdata = csource[csource['Outlier'] != 1]
print("Min to Max Values for Quantity, Price, Expenditure & Consumption")
print("Quantity: " + str(cdata['Quantity'].min()) + " to " + str(cdata['Quantity'].max()))
print("Price: " + str(cdata['Price'].min()) + " to " + str(cdata['Price'].max()))
print("Expenditure: " + str(cdata['Expenditure'].min()) + " to " + str(cdata['Expenditure'].max()))
print("Consumption: " + str(cdata['Consumption'].min()) + " to " + str(cdata['Consumption'].max()))


#3 - calculate a percent difference between our updated searches and the cdata search for Outlier == 0.
# when we follow the min/maxes from above. What kind of perc. match do we get?
datanew = cdata[:]
cdatanew['Quantity'] = csource['Quantity'].where(csource['Quantity'].between(0.001, 1337))
cdatanew['Price'] = csource['Price'].where(csource['Price'].between(2, 20))
cdatanew['Expenditure'] = csource['Expenditure'].where(csource['Expenditure'].between(0.01, 10000.0))
cdatanew['Consumption'] = csource['Consumption'].where(csource['Consumption'].between(0, 500))


#percmatch calculation between cdata and cdatanew
plt.axis([0.001, 1400, 2, 25])
plt.xlabel('Quantity (grams)')
plt.ylabel('Price ($)')

plt.subplot(1, 2, 1)
plt.title('Obs. with Outliers')
plt.scatter(cdata['Quantity'], cdata['Price'], alpha = 0.5, color = 'teal')

plt.subplot(1, 2, 2)
plt.title('Obs. with Ranges')
plt.scatter(cdatanew['Quantity'], cdatanew['Price'], alpha = 0.5, color = 'magenta')
plt.show()


'''
Step 3: STATISTICAL ANALYSIS
As per StatsCan: 
    "performing interquartile  method to group observations into homogeneuous subsets
    flagging outliers that are further away from the group median then set multiples of the 
    distances between the median and the first and third quartiles."
'''
# WIP


'''
Step 4: MACHINE LEARNING
Create randomized training datasets for outlier & non-outlier data

https://www.oreilly.com/ideas/intro-to-scikit-learn
https://scikit-learn.org/stable/tutorial/basic/tutorial.html
https://www.dataquest.io/blog/sci-kit-learn-tutorial/
'''

# Select which columns we wish to use for machine learning algorithm:
def keep_cols(data, keep_these):
    drop_these = list(set(list(data)) - set(keep_these))
    return data.drop(drop_these, axis = 1)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ASIDE: FIX TEXT COLUMNS, issues with symbology. Regrouped as per below binning
# These columns will be recoded later

# 'Province'
for row in csource:
    provinces = csource['Province'].str.rsplit(" / ", n = 1, expand = True)
    csource["Province"] = provinces[0]
    csource['Province_FR'] = provinces[1]
    break

csource = csource.drop(['Province_FR'], axis = 1)

# 'Source'
for row in csource:
    sources = csource['Source'].str.split("-", n = 1, expand = True)
    csource["Source"] = sources[0]
    csource['Source_Discard'] = sources[1]
    break

csource['Source'] = csource['Source'].replace(['Other '], 'Illegal Sources')\
                                     .replace(['A federal', 'A government'], 'Legal Sources')
                                              
csource = csource.drop(['Source_Discard'], axis = 1)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cfiltered = csource.pipe(keep_cols, \
            ['Outlier', 'Quantity', 'Price', 'Expenditure', 'Consumption', 'Source', 'Province'])
cfiltered.head()
cfiltered = cfiltered.fillna("Not Reported", inplace = False)


# Creating dictionaries for encoding & reverse encoding.
transform_dict = {'Not Reported': -999, 'Legal Sources': 0, 'Illegal Sources': 1, 'Newfoundland and Labrador': 10, \
 'Prince Edward Island': 11, 'Nova Scotia': 12, 'New Brunswick': 13, 'Quebec': 24, 'Ontario': 35, 'Manitoba': 46, \
 'Saskatchewan': 47, 'Alberta': 48, 'British Columbia': 59, 'Yukon': 60, 'Northwest Territories': 61, 'Nunavut': 62}

inverse_transform_dict = {-999: 'Not Reported', 0: 'Legal Sources', 1: 'Illegal Sources', 10: 'Newfoundland and Labrador', \
 11: 'Prince Edward Island', 12: 'Nova Scotia', 13: 'New Brunswick', 24: 'Quebec', 35: 'Ontario', 46: 'Manitoba', \
 47: 'Saskatchewan', 48: 'Alberta', 59: 'British Columbia', 60: 'Yukon', 61: 'Northwest Territories', 62: 'Nunavut'}


# Change encoding to defined numbers using above dictionary
cfiltered = cfiltered.replace(transform_dict, inplace = False)


# Define a training and testing dataset:
feature = cfiltered # feature matrix, typically the full dataset we are working with
target = cfiltered['Outlier'] # target feature we are interested in predicting

source_train, source_test, outlier_train, outlier_test = tts(feature, target, test_size = 0.2, random_state = None)


# clf -> classifier, allows us to define the machine learning method we wish to use.
clf = svm.LinearSVC(random_state = 0)


# train & predict data
pred = clf.fit(source_train, outlier_train)\
          .predict(source_test)


# check accuracy score of the model
print("LinearSVC accuracy : ", accuracy_score(outlier_test, pred, normalize = True))


# Compare outliers & prediction side-by-side to visualize accuracy
compare_results = pd.DataFrame()
compare_results = compare_results.append(source_test)

compare_results['Consumption'].replace(inverse_transform_dict, inplace = True) 
compare_results['Province'].replace(inverse_transform_dict, inplace = True)
compare_results['Source'].replace(inverse_transform_dict, inplace = True)

cols_tomove = ['Outlier']
newcols = (compare_results.columns.drop(cols_tomove).to_list()) + cols_tomove
compare_results = compare_results[newcols]

compare_results['Predicted Outlier'] = pred
